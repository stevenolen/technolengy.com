<?xml version="1.0" encoding="utf-8" ?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:wfw="http://wellformedweb.org/CommentAPI/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Derp-min</title>
    <atom:link href="http://localhost:8080/feed.xml" rel="self" type="application/rss+xml"></atom:link>
    <link>http://localhost:8080</link>
    <description>A sysadmin with a tendency to derp.</description>
    <pubDate>Thu, 21 Jan 2016 00:00:00 +0000</pubDate>
    <generator>Wintersmith - https://github.com/jnordberg/wintersmith</generator>
    <language>en</language>
    <item>
      <title>Docker &quot;Development&quot; on OSX: out of space!</title>
      <link>http://localhost:8080/articles/docker-dev-osx-out-of-disk/</link>
      <pubDate>Thu, 21 Jan 2016 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/docker-dev-osx-out-of-disk/</guid>
      <author></author>
      <description>&lt;p&gt;Using docker-machine/docker-toolbox to do some hefty container lifting? Constantly running out of disk space? A quick resolution to your problem!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;If you’re anything like me, you’ve been creating and toying with docker containers (and maybe docker-compose and the enormous ecosystem of docker tools) in a development environment (hopefully in production too!). If you’re doing dev stuff on OSX with the &lt;a href=&quot;https://www.docker.com/docker-toolbox&quot;&gt;docker-toolbox&lt;/a&gt;, kitematic etc etc you’ve likely found that you if you debug/iterate on the same container builds you’ve filled up that measely 20GB of space that &lt;code&gt;docker-machine&lt;/code&gt; gives you in virtualbox really quickly.  The quickest way to regain some space is to remove those pesky dangling images (courtesy of &lt;a href=&quot;http://stackoverflow.com/questions/32723111/how-to-remove-old-and-unused-docker-images&quot;&gt;this&lt;/a&gt; stackoverflow q):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;docker rm $(docker ps -qa --no-trunc --filter &lt;span class=&quot;string&quot;&gt;&quot;status=exited&quot;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or one even better (as the helpful VonC mentions) is to make an alias to do this (name it however you want, i used the keyword ‘docker’ so I could remind myself with tab completion):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;Steves-MacBook-Pro:~ steve$ cat ~/.bash_profile | grep none
&lt;span class=&quot;built_in&quot;&gt;alias&lt;/span&gt; docker-rm-dangling=&lt;span class=&quot;string&quot;&gt;'docker rmi $(docker images --filter &quot;dangling=true&quot; -q --no-trunc)'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At some point, you’ll still end up hitting a wall.  Bloated container sizes or just &lt;em&gt;many, many&lt;/em&gt; containers – you’re going to need some more space. Thankfully docker-machine makes that exceedingly simple.  I’ll assume you don’t need to save any data (it’s just dev, afterall). You can quickly swap from 20G to 50G with this:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;docker-machine rm default
docker-machine create --driver virtualbox --virtualbox-disk-size &lt;span class=&quot;string&quot;&gt;&quot;50000&quot;&lt;/span&gt; --virtualbox-memory &lt;span class=&quot;string&quot;&gt;&quot;2048&quot;&lt;/span&gt; default
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should get me out of that bind for a good long while!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Chef-Vault and a Fantastic Blunder</title>
      <link>http://localhost:8080/articles/chef-vault-and-a-fantastic-blunder/</link>
      <pubDate>Wed, 29 Apr 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/chef-vault-and-a-fantastic-blunder/</guid>
      <author></author>
      <description>&lt;p&gt;This morning, like some other mornings, I really screwed one up! It’s never fun to admit, but it is a part of life and in the spirit of openness I’ll just do my best to embrace it!
Some background: I really, really love &lt;a href=&quot;https://github.com/Nordstrom/chef-vault&quot;&gt;chef-vault&lt;/a&gt;. Apparently this morning I also really forgot how it works when I stupidly reset my chef
private key. In case you ever make this amazing mistake, here’s how I went about resolving it!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I love having my chef cookbooks as open as possible, so in turn I really love using chef-vault to quickly and effectively privatize any (even potentially) private content! 
It’s a breath of fresh air to anyone who has tried to manage encrypted databags on their own, or even just tried to manually set node attributes from the chef web manager for private content. Very briefly, it works by using the existing chef certificate method to encrypt a data bag such that your chef private key, the chef private keys of your other admins and any node that matches a search query is able to decrypt the data bag. It, in my opinion, is far superior to the traditional shared-secret approach of chef encrypted data bags.&lt;/p&gt;
&lt;p&gt;Unfortunately, I really goofed this morning. I made a new organization on my chef server and for some unknown reason I decided to grab the ‘starter kit’ instead of setting the validation key for the new org (resulting in the regeneration of my chef user private key). Hey! Bad news! chef-vault uses that private key to decrypt my vaults! So when I went to edit a vault item, I was met with this wonderful exception:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ERROR: ChefVault::Exceptions::SecretDecryption: vault/item is encrypted for you, but your private key failed to decrypt the contents.  (if you regenerated your client key, have an administrator of the vault run &amp;#39;knife vault refresh&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Well certainly that’s no problem I’ll just have a vault admin run the comm…oh. my only other vault administrator hasn’t set up their keys yet. Great. Now what? I can go through the lengthy process of getting all of the private content from each host where it’s been dropped and piece the bags back together – but i’ve got loads of pieces in different places, and their format on disk is slightly different than the data bag storage. Thankfully, I still had this old key around that I could use!&lt;/p&gt;
&lt;p&gt;The real fun starts! I wanted to use &lt;code&gt;knife vault show&lt;/code&gt; or &lt;code&gt;knife vault edit&lt;/code&gt; to get the current state of the bags, but now I have two keys: 1) gets me authenticated with chef, but wont decrypt the bags, 2) decrypts the bags but wont authenticate me with chef! So I dug down into the chef-vault code to see how they were handling this and did a one-line patch to &lt;a href=&quot;https://github.com/Nordstrom/chef-vault/blob/17385e5610ff17be848f6848942658abe863bb17/lib/chef-vault/item.rb#L103&quot;&gt;this file&lt;/a&gt; (note I’ve used a git commit ref in case the line number changes in the future!) to:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-ruby&quot;&gt;private_key = &lt;span class=&quot;symbol&quot;&gt;OpenSSL:&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:PKey&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;symbol&quot;&gt;:RSA&lt;/span&gt;.new(open(&lt;span class=&quot;string&quot;&gt;'/path/to/old/key.pem'&lt;/span&gt;).read())
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which allowed knife to use the normal chef key to grab the data bag, but chef-vault to use my old key to decrypt! A total hack, but a fun way to fix a stupid problem caused by yours truly. &lt;/p&gt;
</description>
    </item>
    <item>
      <title>Test Kitchen on Docker with Kitematic</title>
      <link>http://localhost:8080/articles/kitchen-ci-on-docker-with-kitematic/</link>
      <pubDate>Tue, 28 Apr 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/kitchen-ci-on-docker-with-kitematic/</guid>
      <author></author>
      <description>&lt;p&gt;I’ve had the great opportunity in the past 4 or so months to really get going with chef, and writing automated infrastructure.
It’s an incredibly deep world/community filled with loads of wonderful people and tools.  One of the best tools for writing
quality chef cookbooks is &lt;a href=&quot;http://kitchen.ci&quot;&gt;Test Kitchen&lt;/a&gt;. Test Kitchen by default uses a vagrant/virtual box environment to
quickly converge and test a chef cookbook.  But I’m ready to push this forward with docker for speed of convergence! Even better,
I use a mac for my local machine and the docker team released an awesome beta of &lt;a href=&quot;https://kitematic.com/&quot;&gt;Kitematic&lt;/a&gt; to facilitate docker
containers on Mac OS. Getting them set up together requires very little effort, but I wanted to note it here in case it was helpful! &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Kitematic works extremely (hey, I haven’t used it so maybe it’s identical to) similarly to boot2docker.  Sean (who wrote the &lt;a href=&quot;https://github.com/portertech/kitchen-docker&quot;&gt;kitchen-docker&lt;/a&gt;  driver) offers an example for getting this working with boot2docker, which I only slightly extended.&lt;/p&gt;
&lt;p&gt;First, get kitchen-docker installed via &lt;code&gt;gem install kitchen-docker&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Second, export a few environment variables (or put these in your `.bash_profile):&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; DOCKER_HOST=tcp://192.168.99.100:2376
&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; DOCKER_CERT_PATH=~/.docker/machine/machines/default
&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; DOCKER_TLS_VERIFY=1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, modify the driver in your &lt;code&gt;.kitchen.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-yaml&quot;&gt;&lt;span class=&quot;meta&quot;&gt;---&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;driver:&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;  name:&lt;/span&gt; docker
&lt;span class=&quot;attr&quot;&gt;driver_config:&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;  require_chef_omnibus:&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;  use_sudo:&lt;/span&gt; &lt;span class=&quot;literal&quot;&gt;false&lt;/span&gt;
[rest of config here]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And finally: make sure kitematic is running and get going with your tests: &lt;code&gt;kitchen test&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That’s it! Thanks!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>Auto Deploys using wintersmith, travisci and github pages</title>
      <link>http://localhost:8080/articles/auto-deploys-with-wintersmith-and-github-pages/</link>
      <pubDate>Mon, 16 Feb 2015 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/auto-deploys-with-wintersmith-and-github-pages/</guid>
      <author></author>
      <description>&lt;p&gt;My latest attempt at a blog has been dead for nearly a year. Why run a wordpress install for a few posts from a year back, right?
So I moved the content to a &lt;a href=&quot;http://wintersmith.io&quot;&gt;wintersmith&lt;/a&gt; template and hooked into a &lt;a href=&quot;https://travis-ci.org/&quot;&gt;TravisCI&lt;/a&gt; build to send the compiled
static content back to github for hosting on github pages. Here’s how I did it!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Unsuprisingly, I didn’t come up with this process on my own. However, while searching I couldn’t find anyone who had used TravisCI and wintersmith in particular, so maybe this will be helpful to someone, somewhere! My goal was to use only one github repository to host the wintersmith (jade assets and plugins) and the compiled code to be served on github pages.  First, I grabbed
wintersmith from npm with &lt;code&gt;npm install -g wintersmith&lt;/code&gt; and initiated a default blog template: &lt;code&gt;wintersmith new technolengy.com&lt;/code&gt;. After modifying the content to my pleasing (as you can likely tell, I didn’t even bother changing the CSS one bit. If it were socially acceptable I’d probably just serve unstyled text) I commited this to master on a github repo and set up the TravisCI integration. &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Grab an account from &lt;a href=&quot;https://travis-ci.org/&quot;&gt;TravisCI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;create a new github token for public repos from &lt;a href=&quot;https://github.com/settings/applications&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;encrypt that token using the travis ruby gem (&lt;code&gt;gem install travis&lt;/code&gt;)&lt;ul&gt;
&lt;li&gt;&lt;code&gt;travis encrypt -r gh_user/gh_repo &amp;quot;GH_TOKEN=new_token_here&amp;quot;&lt;/code&gt; (you’ll need this output soon)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;check out and commit an orphan branch to your repo&lt;ul&gt;
&lt;li&gt;&lt;code&gt;git checkout --orphan gh-pages&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git rm -rf .&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;touch .nojekyll&lt;/code&gt; (since we don’t need github trying to use jekyll on this repo)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git add .&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git commit -m &amp;#39;some message about gh-pages&amp;#39;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push origin gh-pages&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;add a .travis.yml TravisCI config file to this repository (see the file contents below)&lt;/li&gt;
&lt;li&gt;&lt;p&gt;add a simple bash script to send the build contents back to github pages (again see below)&lt;/p&gt;
&lt;p&gt;And that’s it! Once you’ve hooked your builds into TravisCI, you should have viewable content on github pages! You may also want to add a &lt;code&gt;CNAME&lt;/code&gt; file to your wintersmith ‘contents’ dir to serve these pages from an apex domain.  And one last thing: make sure to turn off “build on pull request” on travis for this repository, don’t want someone else offering a pull request and changing your blog!&lt;/p&gt;
&lt;p&gt;Here are the files (but you can see my latest up-to-date versions by visiting this blog’s source &lt;a href=&quot;https://github.com/stevenolen/technolengy.com&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;h2 .travis.yml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-yml&quot;&gt;&lt;span class=&quot;attr&quot;&gt;language:&lt;/span&gt; node_js
&lt;span class=&quot;attr&quot;&gt;node_js:&lt;/span&gt;
&lt;span class=&quot;bullet&quot;&gt;  -&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;0.10&quot;&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;before_install:&lt;/span&gt;
&lt;span class=&quot;bullet&quot;&gt;  -&lt;/span&gt; npm install wintersmith
&lt;span class=&quot;attr&quot;&gt;script:&lt;/span&gt;
&lt;span class=&quot;bullet&quot;&gt;  -&lt;/span&gt; wintersmith build
&lt;span class=&quot;attr&quot;&gt;after_success:&lt;/span&gt; 
&lt;span class=&quot;bullet&quot;&gt;  -&lt;/span&gt; bash gh-pages-deploy.sh
&lt;span class=&quot;attr&quot;&gt;branches:&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;  only:&lt;/span&gt;
    master
&lt;span class=&quot;attr&quot;&gt;env:&lt;/span&gt; 
&lt;span class=&quot;attr&quot;&gt;  global:&lt;/span&gt;
&lt;span class=&quot;attr&quot;&gt;    secure:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;secure_token_here_quoted&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;h2 gh-pages-deploy.sh&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; build
git init
git config user.name &lt;span class=&quot;string&quot;&gt;&quot;Travis-CI&quot;&lt;/span&gt;
git config user.email &lt;span class=&quot;string&quot;&gt;&quot;travis@email.com&quot;&lt;/span&gt;
git add .
git commit -m &lt;span class=&quot;string&quot;&gt;&quot;Deployed to Github Pages&quot;&lt;/span&gt;
git push --force --quiet &lt;span class=&quot;string&quot;&gt;&quot;https://&lt;span class=&quot;variable&quot;&gt;${GH_TOKEN}&lt;/span&gt;@github.com/gh_user/gh_repo&quot;&lt;/span&gt; master:gh-pages &amp;gt; /dev/null 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    <item>
      <title>request-tracker4 sqlite woes</title>
      <link>http://localhost:8080/articles/rt4-sqlite-woes/</link>
      <pubDate>Mon, 24 Feb 2014 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/rt4-sqlite-woes/</guid>
      <author></author>
      <description>&lt;p&gt;My team has been using RT (or request-tracker4) as a ticketing system to manage incoming requests. As with most new system implementations in a group as small as mine is, we can hit the ground running and just make changes/adjust as needed.  This one made me a bit frustrated, so I figured I’d share in case it helped someone else.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;When you install request-tracker4 using the ubuntu 12.04 packages, the packages by default use sqlite (which is fine, yadda yadda, since it’s easier to set up). The annoyance here is that RT doesn’t readily support version upgrades when using sqlite (only mysql and postgres). &lt;/p&gt;
&lt;p&gt;Well, we ended up with a good 6-8 months of usage on the sqlite db but now I wanted to upgrade to a newer version! Off to migrate the sqlite db to mysql.  While sql is sql, there are some distinct inconsistencies between sqlite and mysql, so dump-&amp;gt;import wouldn’t work (and, based on some searches, folks were having trouble with this conversion for RT specifically.  I wrote a little bash script to manage the process (so I could test on a clone of my vm, then perform on the live version).  It worked perfectly, so I’ll leave it below! &lt;/p&gt;
&lt;p&gt;I used a root account for this (in addition to a mysql root account, since the RT db init process was extremely temperamental), and don’t forget to change the RT_SiteConfig.pm file as suggested in the script! Some extra datatype conversions were necessary, since some sqlite columns supported NULL when the mysql equivalent did not.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;&lt;span class=&quot;meta&quot;&gt;#!/bin/bash&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;#converts a request-tracker 4.0.4 sqlite database to mysql&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;#run me as root, or adjust accordingly&lt;/span&gt;

&lt;span class=&quot;comment&quot;&gt;####BEFORE RUNNING####&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##edit /etc/request-tracker4/RT_SiteConfig.pm&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##Set($DatabaseType, 'mysql');&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##Set($DatabaseHost, 'localhost');&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##Set($DatabasePort, '');&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##Set($DatabaseUser , 'rt_user');&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##Set($DatabasePassword , '{password}');&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;##Set($DatabaseName , 'rt_dbname');&lt;/span&gt;

&lt;span class=&quot;comment&quot;&gt;#best to stop apache before running this, just so we can be sane about data usage.&lt;/span&gt;
service apache2 stop

&lt;span class=&quot;comment&quot;&gt;#create table list&lt;/span&gt;
&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; tables=&lt;span class=&quot;string&quot;&gt;&quot;ACL
Articles
Attachments
Attributes
CachedGroupMembers
Classes
CustomFieldValues
CustomFields
GroupMembers
Groups
Links
ObjectClasses
ObjectCustomFieldValues
ObjectCustomFields
ObjectTopics
Principals
Queues
ScripActions
ScripConditions
Scrips
Templates
Tickets
Topics
Transactions
Users&quot;&lt;/span&gt;



&lt;span class=&quot;comment&quot;&gt;#init the rt mysql database, remove pre-created data, since we don't want it.&lt;/span&gt;
rt-setup-database --action init --dba root
&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$tables&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;do&lt;/span&gt;
    mysql -urt_user -p{password} rt_dbname &lt;span class=&quot;_&quot;&gt;-e&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;delete from &lt;span class=&quot;variable&quot;&gt;$i&lt;/span&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;comment&quot;&gt;#copy existing sqlite database (so we don't overwrite), file location based on installation method&lt;/span&gt;
mkdir -p /tmp/rt_sqlite
cp /var/lib/dbconfig-common/sqlite3/request-tracker4/rtdb /tmp/rt_sqlite/rtdb.sqlite


&lt;span class=&quot;comment&quot;&gt;#write our sqlite commands to a temporary file. notice the null commands at the beginning.&lt;/span&gt;
&lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;update Templates set TranslationOf=0 where TranslationOf is NULL;
update Tickets set IssueStatement=0 where IssueStatement is NULL;
update Tickets set Resolution=0 where Resolution is NULL;
update Transactions set TimeTaken=0 where TimeTaken is NULL;
update Tickets set InitialPriority=0 where InitialPriority is NULL;
update Tickets set FinalPriority=0 where FinalPriority is NULL;
update Tickets set TimeEstimated=0 where TimeEstimated is NULL;
update Tickets set TimeLeft=0 where TimeLeft is NULL;&quot;&lt;/span&gt; &amp;gt; /tmp/rt_sqlite/rt_sqlite.transactions

&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;variable&quot;&gt;$tables&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;do&lt;/span&gt;
    &lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;.output /tmp/rt_sqlite/data_&lt;span class=&quot;variable&quot;&gt;$i&lt;/span&gt;&quot;&lt;/span&gt; &amp;gt;&amp;gt; /tmp/rt_sqlite/rt_sqlite.transactions
    &lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;.mode insert &lt;span class=&quot;variable&quot;&gt;$i&lt;/span&gt;&quot;&lt;/span&gt; &amp;gt;&amp;gt; /tmp/rt_sqlite/rt_sqlite.transactions
    &lt;span class=&quot;built_in&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;select * from &lt;span class=&quot;variable&quot;&gt;$i&lt;/span&gt;;&quot;&lt;/span&gt; &amp;gt;&amp;gt; /tmp/rt_sqlite/rt_sqlite.transactions
&lt;span class=&quot;keyword&quot;&gt;done&lt;/span&gt;


&lt;span class=&quot;comment&quot;&gt;#export data from sqlite, separate file per table&lt;/span&gt;
sqlite3 /tmp/rt_sqlite/rtdb.sqlite &amp;lt; /tmp/rt_sqlite/rt_sqlite.transactions

&lt;span class=&quot;comment&quot;&gt;#finally, import the data to mysql&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; i &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; `ls -1 /tmp/rt_sqlite/data_*`
&lt;span class=&quot;keyword&quot;&gt;do&lt;/span&gt; 
    mysql -urt_user -p{password} rt_dbname &amp;lt; &lt;span class=&quot;variable&quot;&gt;$i&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;comment&quot;&gt;#let's start apache back up and cross our fingers!&lt;/span&gt;
service apache2 start
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    <item>
      <title>too much byobu!</title>
      <link>http://localhost:8080/articles/too-much-byobu/</link>
      <pubDate>Thu, 19 Sep 2013 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/too-much-byobu/</guid>
      <author></author>
      <description>&lt;p&gt;For the past few years, I’ve been using a screen/tmux replacement that I really like, called &lt;a href=&quot;http://byobu.co/&quot;&gt;byobu&lt;/a&gt;. 
It’s an absolutely fantastic tool, and one that should be looked at, if you’re not at least using screen or tmux (and 
perhaps even if you are using screen or tmux!) Here’s the thing though, byobu in byobu can be a real pain. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;At $job recently, I was finally able to realize a long-planned situation: 
a single home directory per user on all of our servers (done via LDAP and NFS). After my first couple hours in this 
environment I noticed that byobu would try to launch itself each time I logged into a server (and often make my brain 
explode, when byobu runs in byobu, yadda yadda).&lt;/p&gt;
&lt;p&gt;It turns out there are a few ways to handle this.  The first (per &lt;a href=&quot;https://help.ubuntu.com/community/Byobu&quot;&gt;this&lt;/a&gt; 
ubuntu community help page) is to run this parameter when logging in to each host:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;ssh -t remotehost bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But seriously…that’s a pain.  It’s likely the best way to prevent byobu from running on most hosts is just to add 
a simple bash if statement to your .profile:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;lang-bash&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; HOSTNAME=`hostname`
&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; [ &lt;span class=&quot;string&quot;&gt;&quot;&lt;span class=&quot;variable&quot;&gt;$HOSTNAME&lt;/span&gt;&quot;&lt;/span&gt; = &lt;span class=&quot;string&quot;&gt;&quot;host_where_byobu_should_run&quot;&lt;/span&gt; ]; &lt;span class=&quot;keyword&quot;&gt;then&lt;/span&gt;
_byobu_sourced=1 . /usr/bin/byobu-launch
&lt;span class=&quot;keyword&quot;&gt;fi&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One thing to note is that this will probably break &lt;code&gt;byobu-enable&lt;/code&gt;… but who really needs that anyway!&lt;/p&gt;
</description>
    </item>
    <item>
      <title>A place to dump my tales</title>
      <link>http://localhost:8080/articles/a-place-to-dump-my-tales/</link>
      <pubDate>Wed, 18 Sep 2013 00:00:00 +0000</pubDate>
      <guid isPermaLink="true">http://localhost:8080/articles/a-place-to-dump-my-tales/</guid>
      <author></author>
      <description>&lt;p&gt;It was suggested to me by a co-worker recently that I should blog some of my sysadmin-y findings. It’s unlikely that they are particularly show-stopping, or even novel at all…but they may be good as a reference!&lt;/p&gt;
</description>
    </item>
  </channel>
</rss>